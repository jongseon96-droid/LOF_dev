# main.py
import os
import time
import numpy as np
import pandas as pd
import sys
from datetime import datetime # datetimeì´ ì—†ì–´ì„œ ì¶”ê°€

# ì§„í–‰ë¥  í‘œì‹œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ íŒ¨ìŠ¤)
try:
    from tqdm import tqdm
    USE_TQDM = True
except ImportError:
    USE_TQDM = False
    # print("â„¹ï¸ tqdm ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ë¡œê·¸ë¡œ ì§„í–‰ìƒí™©ì„ í‘œì‹œí•©ë‹ˆë‹¤.") # ì£¼ì„ ì²˜ë¦¬í•˜ì—¬ ê¹”ë”í•˜ê²Œ ë§Œë“¦

# ëª¨ë“ˆ ì„í¬íŠ¸ (Path_module ë‚´ì˜ í˜•ì œ íŒŒì¼ë“¤)
try:
    # 1. ë‹¨ë… ì‹¤í–‰ ëª¨ë“œ
    import config as cfg
    import utils
    import data_loader as dl
    import graph_manager as gm
    import matcher
    import visualizer as viz
except ImportError:
    # 2. í†µí•© ëª¨ë“œ
    from . import config as cfg
    from . import utils
    from . import data_loader as dl
    from . import graph_manager as gm
    from . import matcher
    from . import visualizer as viz

def print_step(step_num, total_steps, message):
    """í˜„ì¬ ë‹¨ê³„ì™€ ë©”ì‹œì§€ë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥"""
    print(f"\n[{step_num}/{total_steps}] {message}")
    print("=" * 60)

# =========================================================
# ğŸŒŸ ì „ì²´ ë¡œì§ì„ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ë¡œ ë¶„ë¦¬ (í•µì‹¬)
# =========================================================
def run_path_analysis():
    """
    Path_moduleì˜ 1ë‹¨ê³„ë¶€í„° 5ë‹¨ê³„ê¹Œì§€ì˜ ë³µì¡í•œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ ,
    ì‹œê°í™”ì— í•„ìš”í•œ ëª¨ë“  ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # í”„ë¡œê·¸ë¨ ì „ì²´ ì‹œì‘ ì‹œê°„ ì¸¡ì • (ë‚´ë¶€ ì‹œê°„ ì¸¡ì •ìš©)
    total_start_time = time.time()
    TOTAL_STEPS = 6

    # ê²°ê³¼ íŒŒì¼ëª…ì— ë¶™ì„ ì‹œê°„ ì ‘ë¯¸ì‚¬ ìƒì„±
    time_suffix = utils.get_current_time_str()

    path_file = os.path.join(cfg.COMMON_CSV_DIR, cfg.FILE_NAME_PATHS)
    reg_file = os.path.join(cfg.COMMON_CSV_DIR, cfg.FILE_NAME_REGS)

    # =========================================================
    # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    # =========================================================
    print_step(1, TOTAL_STEPS, "ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì‹œì‘")
    t_start = time.time()

    print(f"   ğŸ“‚ ê²½ë¡œ íŒŒì¼ ë¡œë“œ ì¤‘... ({cfg.FILE_NAME_PATHS})")
    df_paths_sorted = dl.get_sorted_paths(path_file)

    print(f"   ğŸ“‚ ë¦¬ì „ íŒŒì¼ ë¡œë“œ ì¤‘... ({cfg.FILE_NAME_REGS})")
    regions_df = dl.load_regions(reg_file) # ğŸ‘ˆ Region Graph Cache ì´ˆê¸°í™”ì— ì‚¬ìš©

    print("   ğŸ” ì„¸ê·¸ë¨¼íŠ¸ë³„ Waypoint ì¶”ì¶œ ì¤‘...")
    all_waypoints = dl.extract_waypoints_by_segment(df_paths_sorted)

    print("   ğŸš€ ì†ë„/ê±°ë¦¬ ê¸°ë°˜ ì´ìƒì¹˜ í•„í„°ë§ ìˆ˜í–‰ ì¤‘...")
    full_features_df, raw_df_after_sort = dl.process_data_and_extract_features(df_paths_sorted)

    valid_ids = [sid for sid in full_features_df['segment_id'].unique() if len(all_waypoints.get(sid, [])) >= 2]
    full_features_df = full_features_df[full_features_df['segment_id'].isin(valid_ids)].reset_index(drop=True)

    print(f"   âœ… 1ë‹¨ê³„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - t_start:.2f}ì´ˆ)")

    # =========================================================
    # 2. ë¦¬ì „ ë§¤í•‘
    # =========================================================
    print_step(2, TOTAL_STEPS, "ë¦¬ì „ ë§¤í•‘ (Region Assignment)")
    t_start = time.time()

    iterator = full_features_df.iterrows()
    if USE_TQDM:
        iterator = tqdm(full_features_df.iterrows(), total=len(full_features_df), desc="   Processing Regions", unit="seg")

    seg_region_ids = {}
    for _, row in iterator:
        # ì´ ë¶€ë¶„ì€ Region_moduleì´ ì•„ë‹Œ Path_module ë‚´ì˜ dl.assign_nearest_region_id í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        rid = dl.assign_nearest_region_id(regions_df, row['from_lat'], row['from_lon'])
        seg_region_ids[row['segment_id']] = rid

    # ì§€ë„ ì‹œê°í™”ì˜ ì¤‘ì‹¬ì  ê³„ì‚°
    center_lat = np.mean(full_features_df[['from_lat', 'to_lat']].values)
    center_lon = np.mean(full_features_df[['from_lon', 'to_lon']].values)

    print(f"   âœ… 2ë‹¨ê³„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - t_start:.2f}ì´ˆ)")

    # =========================================================
    # 3. ë§µë§¤ì¹­
    # =========================================================
    print_step(3, TOTAL_STEPS, "OSMnx ë§µë§¤ì¹­ (Map Matching)")
    t_start = time.time()

    reg_cache = gm.RegionGraphCache(regions_df)

    matched_lines = matcher.perform_map_matching_by_region(reg_cache, full_features_df, all_waypoints, seg_region_ids)

    print(f"   âœ… 3ë‹¨ê³„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - t_start:.2f}ì´ˆ)")

    # =========================================================
    # 4. ê²½ë¡œ ìŠ¤í‹°ì¹­
    # =========================================================
    print_step(4, TOTAL_STEPS, "ê²½ë¡œ ìŠ¤í‹°ì¹­ ë° ë³‘í•© (Stitching)")
    t_start = time.time()

    seg_rid_list = [seg_region_ids.get(sid) for sid in full_features_df['segment_id']]
    merged_chunks = matcher.stitch_and_merge_paths(reg_cache, matched_lines, seg_rid_list)

    valid_chunks = [ch for ch in merged_chunks if ch and not ch.is_empty]

    final_grouped_lines = viz.group_lines_by_connectivity(valid_chunks)
    all_lines_flat = [line for group in final_grouped_lines for line in group]

    print(f"   âœ… 4ë‹¨ê³„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - t_start:.2f}ì´ˆ)")

    # =========================================================
    # 5. ë³´ê°„(Interpolation)
    # =========================================================
    print_step(5, TOTAL_STEPS, f"ë³´ê°„ (Step: {cfg.INTERP_STEP_M}m)")
    t_start = time.time()

    interp_points = []

    if cfg.DO_INTERPOLATE and cfg.INTERP_MODE == "merged_global" and all_lines_flat:
        lines_coords = utils.merge_and_simplify_lines(all_lines_flat)
        interp_points = utils.interpolate_continuous_coords_global(lines_coords, cfg.INTERP_STEP_M)
    else:
        print("   âš ï¸ ë³´ê°„ ì˜µì…˜ì´ êº¼ì ¸ìˆê±°ë‚˜ ë°ì´í„°ê°€ ì—†ì–´ ë³´ê°„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    print(f"   âœ… 5ë‹¨ê³„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - t_start:.2f}ì´ˆ)")


    # 6. ìµœì¢… ê²°ê³¼ ë°˜í™˜ (ì‹œê°í™” ë° ì €ì¥ì€ run_analysis.pyê°€ ì²˜ë¦¬)
    return {
        'center_coords': (center_lat, center_lon),
        'final_grouped_lines': final_grouped_lines, 
        'interp_points': interp_points, 
        'regions_df': regions_df, 
        'total_start_time': total_start_time,
        'raw_path_df': df_paths_sorted, # â¬…ï¸ ì´ë¯¸ ì •ë ¬ëœ Raw ë°ì´í„°(í•„í„°ë§ ì „)ë¥¼ ë°˜í™˜
        'filtered_features_df': full_features_df # â¬…ï¸ í•„í„°ë§ í›„ ì‚¬ìš©ëœ ë©”íƒ€ë°ì´í„°
    }


# =========================================================
# ğŸŒŸ ë°–ì—ì„œ ì‹¤í–‰í•  ë•Œì˜ ë©”ì¸ ë¸”ë¡ (ì´ì „ê³¼ ë‹¬ë¦¬ ë¡œì§ì´ ê°„ë‹¨í•´ì§)
# =========================================================
if __name__ == "__main__":
    
    # 1. Path ë¶„ì„ ì „ì²´ ì‹¤í–‰
    path_results = run_path_analysis()
    
    # 2. Step 6: ì§€ë„ ì‹œê°í™” ë° ì¢…ë£Œ (Standalone ëª¨ë“œì—ì„œëŠ” íŒŒì¼ ì €ì¥ê¹Œì§€ ë‹´ë‹¹)
    print_step(6, 6, "ì§€ë„ ì‹œê°í™” ë° ì¢…ë£Œ")
    
    print("   ğŸ¨ HTML ì§€ë„ ìƒì„± ì¤‘...")
    
    # viz ëª¨ë“ˆì˜ ê¸°ì¡´ ì‹œê°í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ë„ ìƒì„±
    m_final = viz.plot_map_layered_by_group(
        path_results['center_coords'], 
        path_results['matched_lines'] if 'matched_lines' in path_results else None, 
        path_results['final_grouped_lines'], 
        path_results['interp_points']
    )
    
    # ê²°ê³¼ CSV ì €ì¥ (Step 5ì—ì„œ ì²˜ë¦¬ë˜ì—ˆì§€ë§Œ, í•„ìš” ì‹œ ì—¬ê¸°ì„œ ì¶”ê°€ ì²˜ë¦¬ ê°€ëŠ¥)
    
    # HTML ì €ì¥
    time_suffix = utils.get_current_time_str() # ë‹¤ì‹œ ìƒì„±
    out_html = os.path.join(cfg.OUTPUT_PATH, f"Result_Map_Standalone_{time_suffix}.html")
    m_final.save(out_html)
    print(f"      -> ì§€ë„ ì €ì¥ë¨: {out_html}")
    
    # ìµœì¢… ì‹œê°„ ì¶œë ¥
    total_elapsed = time.time() - path_results['total_start_time']
    print("\n" + "=" * 60)
    print(f"ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"â±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: {total_elapsed // 60:.0f}ë¶„ {total_elapsed % 60:.2f}ì´ˆ")
    print("=" * 60)