import os
import time
import numpy as np
import pandas as pd
import sys

# ì§„í–‰ë¥  í‘œì‹œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ íŒ¨ìŠ¤)
try:
    from tqdm import tqdm
    USE_TQDM = True
except ImportError:
    USE_TQDM = False
    print("â„¹ï¸ tqdm ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ë¡œê·¸ë¡œ ì§„í–‰ìƒí™©ì„ í‘œì‹œí•©ë‹ˆë‹¤.")

# ëª¨ë“ˆ ì„í¬íŠ¸
import config as cfg
import utils
import data_loader as dl
import graph_manager as gm
import matcher
import visualizer as viz

def print_step(step_num, total_steps, message):
    """í˜„ì¬ ë‹¨ê³„ì™€ ë©”ì‹œì§€ë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥"""
    print(f"\n[{step_num}/{total_steps}] {message}")
    print("=" * 60)

if __name__ == "__main__":
    # í”„ë¡œê·¸ë¨ ì „ì²´ ì‹œì‘ ì‹œê°„ ì¸¡ì •
    total_start_time = time.time()
    
    # ê²°ê³¼ íŒŒì¼ëª…ì— ë¶™ì„ ì‹œê°„ ì ‘ë¯¸ì‚¬ ìƒì„± (ì˜ˆ: _20231127_2030)
    time_suffix = utils.get_current_time_str()
    
    path_file = os.path.join(cfg.COMMON_CSV_DIR, cfg.FILE_NAME_PATHS)
    reg_file  = os.path.join(cfg.COMMON_CSV_DIR, cfg.FILE_NAME_REGS)
    
    TOTAL_STEPS = 6

    # =========================================================
    # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    # =========================================================
    print_step(1, TOTAL_STEPS, "ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì‹œì‘")
    t_start = time.time()
    
    print(f"   ğŸ“‚ ê²½ë¡œ íŒŒì¼ ë¡œë“œ ì¤‘... ({cfg.FILE_NAME_PATHS})")
    df_paths_sorted = dl.get_sorted_paths(path_file)
    
    print(f"   ğŸ“‚ ë¦¬ì „ íŒŒì¼ ë¡œë“œ ì¤‘... ({cfg.FILE_NAME_REGS})")
    regions_df = dl.load_regions(reg_file)
    
    print("   ğŸ” ì„¸ê·¸ë¨¼íŠ¸ë³„ Waypoint ì¶”ì¶œ ì¤‘...")
    all_waypoints = dl.extract_waypoints_by_segment(df_paths_sorted)
    
    print("   ğŸš€ ì†ë„/ê±°ë¦¬ ê¸°ë°˜ ì´ìƒì¹˜ í•„í„°ë§ ìˆ˜í–‰ ì¤‘...")
    full_features_df, _ = dl.process_data_and_extract_features(df_paths_sorted)
    
    # Waypointê°€ 2ê°œ ë¯¸ë§Œì¸(ì  í•˜ë‚˜ë§Œ ì°íŒ) ì˜ë¯¸ ì—†ëŠ” ì„¸ê·¸ë¨¼íŠ¸ ì œê±°
    valid_ids = [sid for sid in full_features_df['segment_id'].unique() if len(all_waypoints.get(sid, [])) >= 2]
    full_features_df = full_features_df[full_features_df['segment_id'].isin(valid_ids)].reset_index(drop=True)
    
    print(f"   âœ… 1ë‹¨ê³„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - t_start:.2f}ì´ˆ)")
    print(f"      - ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(full_features_df)}ê°œ")

    # =========================================================
    # 2. ë¦¬ì „ ë§¤í•‘ (ê° ê²½ë¡œê°€ ì–´ëŠ ì§€ì—­ì— ì†í•˜ëŠ”ì§€ íŒë³„)
    # =========================================================
    print_step(2, TOTAL_STEPS, "ë¦¬ì „ ë§¤í•‘ (Region Assignment)")
    t_start = time.time()
    
    print("   ğŸŒ ê° ê²½ë¡œì˜ ì‹œì‘ì ì„ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ë¦¬ì „ IDë¥¼ ì°¾ìŠµë‹ˆë‹¤...")
    
    # tqdmì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ë¥  í‘œì‹œ (ë°ì´í„°ê°€ ë§ì„ ê²½ìš° ì˜¤ë˜ ê±¸ë¦¼)
    iterator = full_features_df.iterrows()
    if USE_TQDM:
        iterator = tqdm(full_features_df.iterrows(), total=len(full_features_df), desc="   Processing Regions", unit="seg")
    
    seg_region_ids = {}
    for _, row in iterator:
        rid = dl.assign_nearest_region_id(regions_df, row['from_lat'], row['from_lon'])
        seg_region_ids[row['segment_id']] = rid
        
    # ì§€ë„ ì‹œê°í™”ì˜ ì¤‘ì‹¬ì  ê³„ì‚°
    center_lat = np.mean(full_features_df[['from_lat', 'to_lat']].values)
    center_lon = np.mean(full_features_df[['from_lon', 'to_lon']].values)

    print(f"   âœ… 2ë‹¨ê³„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - t_start:.2f}ì´ˆ)")

    # =========================================================
    # 3. ë§µë§¤ì¹­ (ê°€ì¥ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…)
    # =========================================================
    print_step(3, TOTAL_STEPS, "OSMnx ë§µë§¤ì¹­ (Map Matching)")
    t_start = time.time()
    
    print("   ğŸ—ºï¸  OSM ë„ë¡œë§ ê·¸ë˜í”„ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ê²½ë¡œë¥¼ ë§¤ì¹­í•©ë‹ˆë‹¤.")
    print("       (ë„¤íŠ¸ì›Œí¬ ìƒíƒœì— ë”°ë¼ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...)")
    
    # ê·¸ë˜í”„ ìºì‹œ ì´ˆê¸°í™”
    reg_cache = gm.RegionGraphCache(regions_df)
    
    # ë§µë§¤ì¹­ ìˆ˜í–‰ (matcher ëª¨ë“ˆ ë‚´ë¶€ì—ì„œ ìˆ˜í–‰)
    # íŒ: matcher.py ë‚´ë¶€ ë£¨í”„ì— tqdmì„ ë‹¬ë©´ ë” ì¢‹ì§€ë§Œ, ì™¸ë¶€ì—ì„œ ê°ì‹¸ê¸°ëŠ” ì–´ë ¤ìš°ë¯€ë¡œ ì‹œê°„ë§Œ ì¸¡ì •
    matched_lines = matcher.perform_map_matching_by_region(reg_cache, full_features_df, all_waypoints, seg_region_ids)
    
    success_count = sum(1 for ln in matched_lines if ln is not None)
    print(f"   âœ… 3ë‹¨ê³„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - t_start:.2f}ì´ˆ)")
    print(f"      - ë§¤ì¹­ ì„±ê³µë¥ : {success_count} / {len(matched_lines)} ({success_count/len(matched_lines)*100:.1f}%)")

    # =========================================================
    # 4. ê²½ë¡œ ìŠ¤í‹°ì¹­ (ëŠì–´ì§„ ê²½ë¡œ ì‡ê¸°)
    # =========================================================
    print_step(4, TOTAL_STEPS, "ê²½ë¡œ ìŠ¤í‹°ì¹­ ë° ë³‘í•© (Stitching)")
    t_start = time.time()
    
    print(f"   ğŸ§µ ëŠì–´ì§„ ê²½ë¡œë¥¼ ì—°ê²°í•©ë‹ˆë‹¤ (Gap Limit: {cfg.GAP_BREAK_M}m, Max Bridge: {cfg.MAX_BRIDGE_TRY_M}m)")
    
    seg_rid_list = [seg_region_ids.get(sid) for sid in full_features_df['segment_id']]
    merged_chunks = matcher.stitch_and_merge_paths(reg_cache, matched_lines, seg_rid_list)
    
    # ìœ íš¨í•œ ì²­í¬ë§Œ ë‚¨ê¸°ê¸°
    valid_chunks = [ch for ch in merged_chunks if ch and not ch.is_empty]
    
    # ì‹œê°í™”ë¥¼ ìœ„í•´ ê³µê°„ì ìœ¼ë¡œ ì—°ê²°ëœ ê·¸ë£¹ë¼ë¦¬ ë¬¶ê¸°
    print("   ğŸ§© ê³µê°„ì  ì—°ê²°ì„± ë¶„ì„ ì¤‘...")
    final_grouped_lines = viz.group_lines_by_connectivity(valid_chunks)
    all_lines_flat = [line for group in final_grouped_lines for line in group]
    
    print(f"   âœ… 4ë‹¨ê³„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - t_start:.2f}ì´ˆ)")
    print(f"      - ìµœì¢… ìƒì„±ëœ ê²½ë¡œ ì²­í¬: {len(valid_chunks)}ê°œ")
    print(f"      - í˜•ì„±ëœ ê³µê°„ ê·¸ë£¹: {len(final_grouped_lines)}ê°œ")

    # =========================================================
    # 5. ë³´ê°„(Interpolation) ë° CSV ì €ì¥
    # =========================================================
    print_step(5, TOTAL_STEPS, f"ë³´ê°„ ë° ê²°ê³¼ ì €ì¥ (Step: {cfg.INTERP_STEP_M}m)")
    t_start = time.time()
    
    interp_points = []
    
    if cfg.DO_INTERPOLATE and cfg.INTERP_MODE == "merged_global" and all_lines_flat:
        print("   ğŸ”¥ ê²½ë¡œ í†µí•©(Union/Merge) ë° ë³´ê°„ ìˆ˜í–‰ ì¤‘...")
        
        # 1. ê²¹ì¹˜ëŠ” ê²½ë¡œ í•˜ë‚˜ë¡œ ë…¹ì´ê¸° (Melting)
        lines_coords = utils.merge_and_simplify_lines(all_lines_flat)
        
        # 2. ì§€ì •ëœ ê°„ê²©ìœ¼ë¡œ ì  ì°ê¸°
        interp_points = utils.interpolate_continuous_coords_global(lines_coords, cfg.INTERP_STEP_M)
        
        # 3. ë³´ê°„ëœ ì  CSV ì €ì¥
        out_csv = os.path.join(cfg.OUTPUT_PATH, f"mergedGLOBAL_interpolated_{int(cfg.INTERP_STEP_M)}m{time_suffix}.csv")
        df_interp = pd.DataFrame(interp_points, columns=['lat', 'lon'])
        utils.safe_write_csv(df_interp, out_csv)
        print(f"      -> ë³´ê°„ ë°ì´í„° ì €ì¥ë¨: {out_csv}")
        
        # 4. LOF ì…ë ¥ìš© ë°ì´í„° ì €ì¥
        # (ì—¬ê¸°ì„œ ë‚˜ì¤‘ì— ì¤‘ë³µ ì œê±°(dedup)ë‚˜ ë¡œê·¸ ìƒ˜í”Œë§ ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŒ)
        lof_csv = os.path.join(cfg.OUTPUT_PATH, f"lof_input_{int(cfg.INTERP_STEP_M)}m{time_suffix}.csv")
        
        # ì˜ˆì‹œ: ì¢Œí‘œ ë°˜ì˜¬ë¦¼ í›„ ì¤‘ë³µ ì œê±° ë¡œì§ (ì„ íƒì‚¬í•­)
        # df_interp['lat_r'] = df_interp['lat'].round(cfg.DEDUP_PRECISION)
        # df_interp['lon_r'] = df_interp['lon'].round(cfg.DEDUP_PRECISION)
        # df_interp = df_interp.drop_duplicates(subset=['lat_r', 'lon_r'])
        
        utils.safe_write_csv(df_interp[['lat', 'lon']], lof_csv)
        print(f"      -> LOF ì…ë ¥ ë°ì´í„° ì €ì¥ë¨: {lof_csv}")
        print(f"      -> ì´ í¬ì¸íŠ¸ ìˆ˜: {len(df_interp)}ê°œ")

    else:
        print("   âš ï¸ ë³´ê°„ ì˜µì…˜ì´ êº¼ì ¸ìˆê±°ë‚˜ ë°ì´í„°ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")

    print(f"   âœ… 5ë‹¨ê³„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - t_start:.2f}ì´ˆ)")

    # =========================================================
    # 6. ì§€ë„ ì‹œê°í™” ë° ì¢…ë£Œ
    # =========================================================
    print_step(6, TOTAL_STEPS, "ì§€ë„ ì‹œê°í™” (Visualization)")
    t_start = time.time()
    
    print("   ğŸ¨ HTML ì§€ë„ ìƒì„± ì¤‘...")
    m_final = viz.plot_map_layered_by_group(
        (center_lat, center_lon), matched_lines, final_grouped_lines, interp_points
    )
    
    out_html = os.path.join(cfg.OUTPUT_PATH, f"Result_Map{time_suffix}.html")
    m_final.save(out_html)
    print(f"      -> ì§€ë„ ì €ì¥ë¨: {out_html}")
    
    print(f"   âœ… 6ë‹¨ê³„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - t_start:.2f}ì´ˆ)")

    # í”„ë¡œê·¸ë¨ ì¢…ë£Œ
    total_elapsed = time.time() - total_start_time
    print("\n" + "=" * 60)
    print(f"ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"â±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: {total_elapsed // 60:.0f}ë¶„ {total_elapsed % 60:.2f}ì´ˆ")
    print("=" * 60)